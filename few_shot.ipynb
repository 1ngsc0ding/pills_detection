{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 11:31:38.952525: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-08 11:31:42.018303: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import random\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 5\n",
    "NUM_SAMPLES_PER_CLASS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 90 images.\n"
     ]
    }
   ],
   "source": [
    "PATH = \"/mnt/d/Numing/projects/aibuilders/pills_detection/dataset2/test/images\"\n",
    "\n",
    "# Get all images\n",
    "all_files = list()\n",
    "for (dirpath, dirnames, filenames) in os.walk(PATH):\n",
    "    all_files += [os.path.join(dirpath, file) for file in filenames]\n",
    "print(f\"The dataset contains {len(all_files)} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_propocess_image(img_path, image_dim=None):\n",
    "    \"\"\"\n",
    "    Takes an image path and returns a grayscale, resized, and flattened image as array\n",
    "    \n",
    "    Args:\n",
    "    * img_path: Full path to file\n",
    "    * image_dim: Resized image shape (width, height)\n",
    "    \n",
    "    Returns:\n",
    "    a grayscale, resized, and flattened image\n",
    "    \"\"\"\n",
    "    # Read image as grayscale\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Resize image\n",
    "    if image_dim is not None:\n",
    "        img = cv2.resize(img, image_dim, interpolation = cv2.INTER_AREA) \n",
    "    \n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    img = 1.0 - img\n",
    "    img = img.reshape(-1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "class DataLoader():\n",
    "    \"\"\"\n",
    "    Data Loader Few-Shot Learning \n",
    "    Forked from https://github.com/cbfinn/maml\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, num_samples_per_class):\n",
    "        \"\"\"\n",
    "        args:\n",
    "        * num_classes: N classes in support set \n",
    "        * num_samples_per_class: K samples per class in support set\n",
    "        \"\"\"\n",
    "        self.num_classes = num_classes\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        print(f\"Data Loader for {num_classes}-way, {num_samples_per_class}-shot Few-Shot Learning.\")\n",
    "        \n",
    "        # Dataset specific\n",
    "        self.meta_train_folders = \"/mnt/d/Numing/projects/aibuilders/pills_detection/dataset2/train/images\"\n",
    "        self.meta_val_folders = \"/mnt/d/Numing/projects/aibuilders/pills_detection/dataset2/validation/images\"\n",
    "        self.meta_test_folders = \"/mnt/d/Numing/projects/aibuilders/pills_detection/dataset2/test/images\"\n",
    "    \n",
    "    def sample_batch(self, batch_type, batch_size):\n",
    "        \"\"\"\n",
    "        returns:\n",
    "        * image_batch with shape [batch_size, num_classes, num_samples_per_class, (im_size * im_size)]\n",
    "        * label_batch with shape [batch_size, num_classes, num_samples_per_class, num_classes]\n",
    "        \"\"\"\n",
    "        all_image_batches, all_label_batches = [], []\n",
    "        \n",
    "        # Set the folder according to purpose\n",
    "        if batch_type == 'train':\n",
    "            base_path = self.meta_train_folders\n",
    "        elif batch_type == 'val':\n",
    "            base_path = self.meta_val_folders\n",
    "        elif batch_type == 'test':\n",
    "            base_path = self.meta_test_folders\n",
    "        else: \n",
    "            print(f\"Error: '{batch_type}' is not a valid value for batch_type. batch_type must be either one of 'train', 'val', 'test'.\")\n",
    "        \n",
    "        folders = [os.path.join(base_path, folder, character)\n",
    "                      for folder in os.listdir(base_path)\n",
    "                      for character in os.listdir(os.path.join(base_path, folder))]\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            # Sample N different classes from the folders\n",
    "            sampled_character_folders = random.sample(folders, self.num_classes)\n",
    "\n",
    "            # Sample K images per class and associate labels\n",
    "            sampler = lambda x: random.sample(x, self.num_samples_per_class)\n",
    "            labels_and_images = [(i, os.path.join(path, image)) \\\n",
    "                for i, path in zip(range(self.num_classes), sampled_character_folders) \\\n",
    "                for image in sampler(os.listdir(path))]\n",
    "\n",
    "            labels = [li[0] for li in labels_and_images]\n",
    "            images = [read_and_propocess_image(li[1], (28, 28)) for li in labels_and_images]\n",
    "\n",
    "            # Format images to fit [num_classes, num_samples_per_class, (im_size * im_size)]\n",
    "            images = np.stack(images)\n",
    "            images = np.reshape(images, (self.num_classes, self.num_samples_per_class, -1))\n",
    "\n",
    "            # Format labels one-hot encoded to fit [ num_classes, num_samples_per_class, num_classes]\n",
    "            labels = np.array(labels)\n",
    "            labels = np.reshape(labels, (self.num_classes, self.num_samples_per_class))\n",
    "            labels = np.eye(self.num_classes)[labels]\n",
    "\n",
    "            batch = np.concatenate([labels, images], 2)\n",
    "\n",
    "            # Shuffle classes such that classes are not associated with the order\n",
    "            for p in range(self.num_samples_per_class):\n",
    "                np.random.shuffle(batch[:, p])\n",
    "                \n",
    "            labels = batch[:, :, :self.num_classes]\n",
    "            images = batch[:, :, self.num_classes:]\n",
    "\n",
    "            all_image_batches.append(images)\n",
    "            all_label_batches.append(labels)\n",
    "            \n",
    "        all_image_batches = np.stack(all_image_batches)\n",
    "        all_label_batches = np.stack(all_label_batches)\n",
    "\n",
    "        return all_image_batches, all_label_batches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
